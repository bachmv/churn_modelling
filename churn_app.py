# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIk8ZHW72mMteL2nhKbchpsbPtGMl7bU
"""

import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# Load và xử lý dữ liệu
@st.cache_data
def load_data():
    df = pd.read_csv("Churn_Modelling.csv")
    df = df.drop(columns=["RowNumber", "CustomerId", "Surname"])
    label_encoder = LabelEncoder()
    df["Gender"] = label_encoder.fit_transform(df["Gender"])
    df = pd.get_dummies(df, columns=["Geography"], drop_first=True)
    scaler = StandardScaler()
    numerical_features = ["CreditScore", "Age", "Tenure", "Balance", "NumOfProducts", "HasCrCard", "IsActiveMember", "EstimatedSalary"]
    df[numerical_features] = scaler.fit_transform(df[numerical_features])
    return df

df = load_data()
X = df.drop(columns=["Exited"])
y = df["Exited"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Danh sách model
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Naive Bayes": GaussianNB(),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Random Forest (tuned by GridSearchCV)": RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42),
    "XG Boost": XGBClassifier(eval_metric='logloss', random_state=42),
    "XG Boost (tuned by RandomizedSearchCV)": XGBClassifier(subsample=1.0, n_estimators=300, max_depth=10, learning_rate=0.2, gamma=0.1, colsample_bytree=0.8),
    "Neural Network (MLPClassifier)": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, verbose=True, random_state=42),
    "Stacking (XGBoost + RF + Logistic Regression)": StackingClassifier(estimators=[('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),('rf', RandomForestClassifier(n_estimators=100, random_state=42))], final_estimator=LogisticRegression(), passthrough=False, cv=5, n_jobs=-1)
}

# Hàm so sánh mô hình
def compare_models():
    results = []
    for name, clf in models.items():
        clf.fit(X_resampled, y_resampled)
        y_pred = clf.predict(X_test)
        y_pred_proba = clf.predict_proba(X_test)[:, 1]
        report_dict = classification_report(y_test, y_pred, output_dict=True)
        acc = accuracy_score(y_test, y_pred)
        f1_score = report_dict["macro avg"]["f1-score"]
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        model_auc = auc(fpr, tpr)
        results.append({
            "Model": name,
            "Accuracy": acc,
            "F1-Score": f1_score,
            "AUC": model_auc
        })
    return pd.DataFrame(results)

# Giao diện Streamlit
st.title("Customer Churn Prediction")
st.write("Bài toán phân lớp dự đoán khả năng khách hàng rời bỏ.")

# Chọn chế độ: Dự đoán hoặc So sánh mô hình
mode = st.radio("Chọn chế độ", ["Dự đoán với 1 mô hình", "So sánh mô hình"])

if mode == "So sánh mô hình":
    st.subheader("So sánh các mô hình")
    comparison_df = compare_models()
    st.dataframe(comparison_df.style.format({"Accuracy": "{:.4f}", "F1-Score": "{:.4f}", "AUC": "{:.4f}"}))

    st.subheader("Biểu đồ Accuracy theo mô hình")
    fig_acc, ax_acc = plt.subplots()
    sns.barplot(data=comparison_df, x="Model", y="Accuracy", palette="coolwarm", ax=ax_acc)
    ax_acc.set_ylim(0, 1)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig_acc)

    st.subheader("Biểu đồ F1-Score theo mô hình")
    fig_f1, ax_f1 = plt.subplots()
    sns.barplot(data=comparison_df, x="Model", y="F1-Score", palette="magma", ax=ax_f1)
    ax_f1.set_ylim(0, 1)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig_f1)

    st.subheader("Biểu đồ AUC theo mô hình")
    fig_bar, ax_bar = plt.subplots()
    sns.barplot(data=comparison_df, x="Model", y="AUC", palette="viridis", ax=ax_bar)
    ax_bar.set_ylim(0, 1)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig_bar)

    st.stop()

# Chọn model
model_name = st.selectbox("Chọn mô hình", list(models.keys()))
model = models[model_name]

# Train và dự đoán
model.fit(X_resampled, y_resampled)
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Hiển thị kết quả
accuracy = accuracy_score(y_test, y_pred)
st.metric("Độ chính xác", f"{accuracy:.4f}")

# Classification report
st.subheader("Classification Report")
st.text(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
fig_cm, ax_cm = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Stayed", "Churned"], yticklabels=["Stayed", "Churned"], ax=ax_cm)
plt.xlabel("Dự đoán")
plt.ylabel("Thực tế")
st.subheader("Confusion Matrix")
st.pyplot(fig_cm)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)
fig_roc, ax_roc = plt.subplots()
ax_roc.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color='blue')
ax_roc.plot([0, 1], [0, 1], linestyle="--", color="gray")
ax_roc.set_xlabel("False Positive Rate")
ax_roc.set_ylabel("True Positive Rate")
ax_roc.set_title("ROC Curve")
ax_roc.legend()
st.subheader("ROC Curve")
st.pyplot(fig_roc)